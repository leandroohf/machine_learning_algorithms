{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Linear Discriminant Analysis\n",
    "\n",
    "PLDA is supervised learning. In PLDA assumes that the training data can be generated by known process (given by equation). Therfore it is called a generative model because of that. The PLDA instead of work with distances as measures of similarity, it provides probabilities as measure of similarity. Like in  <a href=\"intro_lda.ipynb\">Fisher LDA</a>, PLDA transform the training data into a new subspace where the discriminativy power is maximized. Below are the main assumpiosn:\n",
    "\n",
    "1. Normal distribution\n",
    "    * All classes are normal distributed: $P(x \\mid y) = N(x \\mid y,\\Phi_w)$\n",
    "    * All class has the same covariance matrix $\\Phi_w$ \n",
    "    * The centroides of each class are normal distributed: $P(y) = N(y|m,\\Phi_b)$. Therefore, PLDA can be extended to unknown classes.\n",
    "3. Each class has the same number of samples $n_k$ (For analytic soltuion, but not for EM solution). Case it is not true, resample the class in order to have all class with the same number of observations or set $n_k$ with average number of sample per class\n",
    "\n",
    "The solution has the constraints:\n",
    "1. $\\Phi_w$ is positive defined\n",
    "2. The priori $P(y) = N(y \\mid 0,\\Phi_b)$ is normal distributed\n",
    "3. $\\Phi_b$ is semi-positive defined\n",
    "\n",
    "See this wiki: [this](https://en.wikipedia.org/wiki/Positive-definite_matrix)\n",
    "\n",
    "Motivations:\n",
    "\n",
    "refs: https://ravisoji.com/assets/papers/Ioffe2006PLDA.pdf (abstract)\n",
    "\n",
    "1. Fisher LDA is common used in object recognition for feature extraction, but do not address the problem of how to use these features for recognition.\n",
    "2. The latent variables of PLDA (PLDA components) represent both: the class of the object and the within variability class of the object.\n",
    "3. Automatic give more weight of the features with the most discriminativy power\n",
    "4. Can build a model of unseen class with only one example or can combine multiple examples for a better representation of the class\n",
    "\n",
    "Application:\n",
    "\n",
    "\n",
    "It is commonly used in biometric authentication and PLDA models perform well in face and speaker recognition\n",
    "\n",
    "* Speaker recognition\n",
    "* Face recogintion\n",
    "\n",
    "For simplicity, the practical aspect of PLDA will be explained utilzing 3 classes example and bi-dimensional data.\n",
    "\n",
    "###  How PLDA works\n",
    "\n",
    "The dataset is a set of $N$ d-dimensional samples $X = \\{x_1, x_2, ..., x_N\\}$ already labeled in 2 groups: \n",
    "$X^{(k)} = \\{ x_1^{(k)},  x_2^{(k)}, ..., x_{n_k}^{(k)} \\}$ of size $n_k$ for $k = 1,2, ..., K$ where $x_i^{(k)}$ is a vector of dimension $d$ and it means the ith sample of the kth class.\n",
    "\n",
    "The figure below, a labeled dataset ($x_i^{(k)}$) contained 3 classes are shown.  The centroides of each class $y = m_k$ are the red points and the global mean is in blue.\n",
    "\n",
    "<img src=\"../images/plda_0.png\" width=\"300\"/>\n",
    "\n",
    "The linear transformation $x' = W^t x$ map $x_i^{(k)}$ in to new set of axis defined by the new subsace $U$ where all class follows standart multivariate normal distribution. And the centroides follows a multivariate normal distribution where the covariance matrix is decorrelated. See the figute below, where the transformed $x_i^{(k)}$ is presented in $U$ subsapce.\n",
    "\n",
    "<img src=\"../images/plda_1.png\" width=\"300\"/>\n",
    "\n",
    "In the figure above, the vertical axis is the axis with the most discriminative power and the horizontal axis can be discarded. PLDA assumes that the training data is generated by:\n",
    "\n",
    "$\n",
    "x = m + Au\n",
    "$\n",
    "\n",
    "and the centroids by\n",
    "\n",
    "$\n",
    "y = m + Av\n",
    "$\n",
    "\n",
    "The subspace defined by $U$ maximize the discriminative power. In order to do that, PLDA like Fisher LDA maximize the ratio \"scatter between classes/scatter within classes\" \n",
    "expressed by the cost function $J(w)$. The problem can be transformed in the generalized eigenvector eigenvalue problem which the solutions are known.\n",
    "\n",
    "$\n",
    "S_b w =  \\lambda S_w w\n",
    "$\n",
    "\n",
    "where:\n",
    "\n",
    "* $S_b= \\frac{1}{N} \\sum_{k=1}^K n_k (m_k - m)( m_k - m)^t$ :  between-class covariance/satter matrix. (Can be understood as measure of between class spread)\n",
    "    \n",
    "* $S_{w} = \\frac{1}{N} \\sum_{k=1}^K S_k$ : within-class covariance/scatter matrices. (Can be understood as measure of within class spread or the sum of the spread matrix of each class) \n",
    "\n",
    "\n",
    "---\n",
    "**NOTE**\n",
    "\n",
    "The difference of this equations and the ones in Fisher's LDA are just the normalization constant $\\frac{1}{N}$. See the notebook <a href=\"intro_lda.ipynb\">intro to Fishers LDA</a>. \n",
    "\n",
    "$S_t$ is the total spread matrix: $S_t = S_w + S_b$  \n",
    "---\n",
    "\n",
    "\n",
    "$ m_k$ is the mean of each class. $m$ is the global mean. and $S_k$ is the spread matrix of each class given by:\n",
    "\n",
    "$\n",
    "S_k = \\sum_{x_i\\in X^{(k)}} ( x_i^{(k)} -  m_k) ( x_i^{(k)} - m_k)^t  \n",
    "$\n",
    "\n",
    "The covariance matrix of each class can be estimated (becomes better as $n_k >> 1$) using the spread matrix:\n",
    "\n",
    "$\n",
    "\\hat{\\Phi_w} = \\frac{1}{n_k -1}S_k  \n",
    "$\n",
    "\n",
    "And the cost function:\n",
    "\n",
    "$\n",
    "J(w) = \\frac{w^t S_{b} w}{ w^t S_{w}  w} \n",
    "$\n",
    "\n",
    "To find a solution to PLDA, we need to determine the 3 learning parameters: $A$ (transform $x$ and $y$), $m$ and $\\Psi$. It is not the scope of this \"personal note\" to demonstrade that, but the solutions can be given by:\n",
    "\n",
    "\n",
    "$\n",
    "A  = W^{-t} \\left ( \\frac{n}{n-1} \\Lambda_w \\right)^{\\frac{1}{2}}\n",
    "$\n",
    "\n",
    "$\n",
    "\\Psi = max(0, \\frac{n-1}{n} (\\Lambda_b/\\Lambda_w) - \\frac{1}{n})\n",
    "$\n",
    "\n",
    "Where: \n",
    "\n",
    "$W$ is a matrix with the column eigenvector stacked that solves the eigenvector egeinvalue generalized problem.\n",
    "\n",
    "$\\boldsymbol W = \\begin{bmatrix}\n",
    " w_1 & w_2 & \\cdots & w_k\n",
    "\\end{bmatrix} \n",
    "$\n",
    "\n",
    "\n",
    "The diagonalized spread matrixes:  \n",
    "\n",
    "$\n",
    "\\Lambda_b = W^t S_b W\n",
    "$\n",
    "\n",
    "$\n",
    "\\Lambda_w = W^t S_w W\n",
    "$\n",
    "\n",
    "\n",
    "Other importants formulas of this solutions are:\n",
    "\n",
    "\n",
    "$\n",
    "\\Phi_w = AA^t\n",
    "$\n",
    "\n",
    "and \n",
    "\n",
    "$\n",
    "\\Phi_b = A \\Psi A^t\n",
    "$\n",
    "\n",
    "---\n",
    "**NOTE**\n",
    "\n",
    "PLDA impose that $\\Phi_w$ is positive defined. So when solve the eigenvecto problem above we need to impose that as well. But I ma not completely sure about that. \n",
    "\n",
    "```python\n",
    "from scipy.linalg import eigh\n",
    "\n",
    "eigenvalues, W = eigh(Sb, Sw)\n",
    "\n",
    "## Doc: eigh(S, b=None, lower=True, eigvals_only=False, overwrite_a=False, overwrite_b=False, turbo=True, eigvals=None, type=1, check_finite=True)\n",
    "## Solve an ordinary or generalized eigenvalue problem for a complex Hermitian or real symmetric matrix.\n",
    "\n",
    "Find eigenvalues w and optionally eigenvectors v of matrix a, where b is positive definite:\n",
    "```  \n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "=============================\n",
    "\n",
    "Transforms an X into a space where the within-class variance is unit and between-class variance is diagonalized.\n",
    "\n",
    "The probability of not belonging to any known class is: \n",
    "\n",
    "P(u_new| 0) = N(u_new| 0, \\Psi + I)\n",
    "\n",
    "$\\boldsymbol W = \\begin{bmatrix}\n",
    " w_1 & w_2 & \\cdots & w_k\n",
    "\\end{bmatrix} \n",
    "$\n",
    "\n",
    "### Summarizing the PLDA approach in 5 steps\n",
    "\n",
    "1. Define $n = N/k$\n",
    "2. Compute the transformations matrixes\n",
    "    * Compute the spread matrixes\n",
    "    * Determine $W$ by solving the $S_b w = \\lambda S_w w $\n",
    "    * Compute the diagonalized spread matrixes $\\Lambda_w$ and $\\Lambda_b$\n",
    "2. Compute the learning parameters \n",
    "    * $m = \\frac{1}{N}\\sum_i^N x_i $\n",
    "    * $ A  = W^{-t} \\left ( \\frac{n}{n-1} \\Lambda_w \\right)^{\\frac{1}{2}} $\n",
    "    * $ \\Psi = max(0, \\frac{n-1}{n} (\\Lambda_b/\\Lambda_w) - \\frac{1}{n})  $\n",
    "3. Reduce dimensionality to $d' < d$\n",
    "    * keep the $d'$ largest elements of $\\Psi$ and set the rest to zero. \n",
    "    * kewp only the features correspondent to non-zero elements of $\\Psi$ in the latent subsapce $u = A^{-1} (x - m)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T20:59:43.791530Z",
     "start_time": "2019-06-03T20:59:43.073985Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import eigh\n",
    "\n",
    "import pandas as pd\n",
    "import random as rand\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:01:12.647053Z",
     "start_time": "2019-06-03T21:01:12.578761Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append('/Users/leandro/Documents/leandro/lda/refs/plda')\n",
    "sys.path.append('/home/leandroohf/Documents/leandro/LDA/refs/plda/')\n",
    "\n",
    "\n",
    "import plda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/home/leandroohf/Documents/leandro/LDA/refs/plda/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:01:16.451785Z",
     "start_time": "2019-06-03T21:01:16.440161Z"
    }
   },
   "outputs": [],
   "source": [
    "def cov_ellipse(cov, q=None, nsig=None, **kwargs):\n",
    "    \"\"\" Code is slightly modified, but essentially borrowed from: \n",
    "         https://stackoverflow.com/questions/18764814/make-contour-of-scatter\n",
    "    \"\"\"\n",
    "    if q is not None:\n",
    "        q = np.asarray(q)\n",
    "    elif nsig is not None:\n",
    "        q = 2 * norm.cdf(nsig) - 1\n",
    "    else:\n",
    "        raise ValueError('Either `q` or `nsig` should be specified')\n",
    "\n",
    "    r2 = chi2.ppf(q, 2)\n",
    "    val, vec = np.linalg.eigh(cov)\n",
    "    width, height = 2 * np.sqrt(val[:, None] * r2)\n",
    "    rotation = np.degrees(np.arctan2(*vec[::-1, 0]))\n",
    "\n",
    "    return width, height, rotation\n",
    "\n",
    "def plot_scatter(ax, x, y, s=5, c='black', label='', plot_training_cov=False,\n",
    "                 model=None):\n",
    "    assert len(x.shape) == 1\n",
    "    assert len(y.shape) == 1\n",
    "    if plot_training_cov is True:\n",
    "        assert model is not None\n",
    "    \n",
    "    ax.scatter(x, y, c=c, s=s, label=label)\n",
    "\n",
    "    if plot_training_cov is True:\n",
    "        cov = model.data[label]['cov']\n",
    "        mean_x, mean_y = model.data[label]['mean']\n",
    "        w, h, deg = cov_ellipse(cov, nsig=2)\n",
    "        ell = Ellipse(xy=(mean_x, mean_y),\n",
    "                      width=w, height=h,\n",
    "                      angle=deg, linewidth=2)\n",
    "        ell.set_facecolor('none')\n",
    "        ell.set_edgecolor('black')\n",
    "        ax.add_patch(ell)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:01:17.806540Z",
     "start_time": "2019-06-03T21:01:17.776198Z"
    }
   },
   "outputs": [],
   "source": [
    "from numpy.random import multivariate_normal as m_normal\n",
    "\n",
    "def gen_training_set(n_gaussians, sample_size, n_dims):\n",
    "    cov = np.random.randint(-10, 10, (n_dims, n_dims))\n",
    "    cov = np.matmul(cov, cov.T) + np.eye(n_dims) * np.random.rand(n_dims)\n",
    "\n",
    "    pts = np.vstack([m_normal(np.ones(n_dims) * np.random.randint(-100, 100, 1),\n",
    "                              cov, sample_size) \\\n",
    "                     for x in range(n_gaussians)])\n",
    "    lbls = np.hstack([['gaussian_{}'.format(x)] * sample_size for x in range(n_gaussians)])\n",
    "\n",
    "    return pts, lbls\n",
    "\n",
    "n_gaussians = 5\n",
    "sample_size = 100\n",
    "n_dims = 2\n",
    "n_test = 5000\n",
    "\n",
    "# Initialize training and test data.\n",
    "np.random.seed(0)\n",
    "train_X, train_Y = gen_training_set(n_gaussians, sample_size, n_dims)\n",
    "\n",
    "margin = np.sqrt(np.cov(train_X.T).diagonal().sum()) * .1\n",
    "(min_x, min_y), (max_x, max_y) = np.min(train_X, axis=0) - margin,\\\n",
    "                                 np.max(train_X, axis=0) + margin\n",
    "\n",
    "test = np.asarray([np.random.uniform(min_x, max_x, n_test),\n",
    "                   np.random.uniform(min_y, max_y, n_test)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:01:19.512165Z",
     "start_time": "2019-06-03T21:01:19.503655Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:01:22.199889Z",
     "start_time": "2019-06-03T21:01:22.135997Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "le.fit(train_Y)\n",
    "\n",
    "labels = le.transform(train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:01:24.195590Z",
     "start_time": "2019-06-03T21:01:23.970117Z"
    },
    "code_folding": [
     2
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(500, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>56.035261</td>\n",
       "      <td>45.631105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>67.634618</td>\n",
       "      <td>82.902492</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>58.644108</td>\n",
       "      <td>39.555890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>52.716556</td>\n",
       "      <td>51.841558</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>37.801160</td>\n",
       "      <td>37.562159</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             x          y  label\n",
       "137  56.035261  45.631105      1\n",
       "405  67.634618  82.902492      4\n",
       "162  58.644108  39.555890      1\n",
       "151  52.716556  51.841558      1\n",
       "250  37.801160  37.562159      2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4374560dd8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%run ../simulated_plda_data.ipynb\n",
    "\n",
    "df = pd.DataFrame(data=train_X, index=None, columns=['x','y'])\n",
    "\n",
    "df['label'] = labels\n",
    "\n",
    "df.label.unique()\n",
    "\n",
    "\n",
    "df.shape\n",
    "\n",
    "x_new = np.array([-50.0,-50.0])\n",
    "\n",
    "\n",
    "X = df[['x','y']].values\n",
    "N = X.shape[0]\n",
    "y = df.label\n",
    "\n",
    "df.label.unique()\n",
    "\n",
    "X1 = df.loc[df.label ==1,['x','y']].values\n",
    "nk = X1.shape[0]\n",
    "\n",
    "N\n",
    "nk\n",
    "\n",
    "df.sample(5).head(5)\n",
    "\n",
    "ax = plt.gca()\n",
    "plot_scatter(ax, train_X[:,0], train_X[:,1], s=5, c=labels, label=labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:01:27.140466Z",
     "start_time": "2019-06-03T21:01:27.122324Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def estimate_gaussian_parameters(Xk):\n",
    "\n",
    "    mk = np.mean(Xk,axis=0)\n",
    "    Sk = np.cov(Xk[:,0],Xk[:,1])\n",
    "    \n",
    "    return mk, Sk\n",
    "\n",
    "def get_plda_paramaters(Xk,N):\n",
    "    \n",
    "    Nk = Xk.shape[0]\n",
    "    \n",
    "    pik = Nk/N\n",
    "    \n",
    "    mk, Sk = estimate_gaussian_parameters(Xk)\n",
    "    \n",
    "    Sk_inv = np.linalg.inv(Sk)\n",
    "    \n",
    "    return Sk_inv, pik\n",
    "\n",
    "def compute_scatter_matrixes(X,y,nk):\n",
    "    \n",
    "    d = X.shape[1]\n",
    "    N = X.shape[0]\n",
    "    \n",
    "    m = np.mean(X,axis=0)\n",
    "    \n",
    "    Sw = np.zeros((d,d))\n",
    "    Sb = np.zeros((d,d))\n",
    "    \n",
    "    labels = np.unique(y)\n",
    "    \n",
    "    for label in labels:\n",
    "    \n",
    "        Xk = np.squeeze(X[np.argwhere(y == label)])\n",
    "        mk, Sk = estimate_gaussian_parameters(Xk)\n",
    "        \n",
    "        # within spread matrix\n",
    "        Sw = np.add(Sw,(nk -1)*Sk/N)\n",
    "        \n",
    "        # between spread matrix\n",
    "        dmk = np.add(mk,-m)\n",
    "        dmk = dmk[np.newaxis].transpose()\n",
    "\n",
    "        Sb = np.add(Sb, nk/N*np.matmul(dmk, dmk.transpose()))\n",
    "    \n",
    "    return Sw, Sb\n",
    "    \n",
    "def diagnolize_matrix(M, W):\n",
    "    \n",
    "    M_diag = np.matmul(W.T,np.matmul(M,W))\n",
    "    M_diag = np.diag(M_diag.diagonal())\n",
    "    \n",
    "    return M_diag\n",
    "    \n",
    "def compute_transformation_matrix(Sw,Sb,nk):\n",
    "    \n",
    "    #Sw_inv = np.linalg.inv(Sw)\n",
    "    d = Sw.shape[0]\n",
    "     \n",
    "    #S = np.matmul(Sw_inv, Sb)\n",
    "    \n",
    "   \n",
    "    # XXX solves the generalized eigenvalue problem:\n",
    "    # Av = \\lambda Bv where B is positive definite (numpy eigh does not have this constraint).\n",
    "    # But I understood that \\Phi_w is positive definte n Phi_b semi positive definite and\n",
    "    # not Sw !?\n",
    "    # https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.eigh.html\n",
    "    # Wtih numpy eigh is not working \n",
    "    eigenvalues, W = eigh(Sb, Sw)\n",
    "    #eigen_values, W = np.linalg.eigh(S)\n",
    "        \n",
    "    # projected/diagnolized within spread matrix: projecting Sw\n",
    "    Lambda_w = diagnolize_matrix(Sw,W)\n",
    "  \n",
    "    weight = nk/(nk - 1)\n",
    "    \n",
    "    Lambda_w_weighted = weight*Lambda_w\n",
    "    # prevent small negative numbers due to numerical error\n",
    "    Lambda_w_weighted[np.isclose(Lambda_w_weighted, 0.0)] = 0.0\n",
    "    Lambda_w_weighted = np.sqrt(Lambda_w_weighted)\n",
    "    \n",
    "    W_transposed_inv = np.linalg.inv(W).T\n",
    "    \n",
    "    A = np.matmul(W_transposed_inv, Lambda_w_weighted)\n",
    "    \n",
    "    return A, W\n",
    "\n",
    "def compute_transformed_between_covariance(Lambda_w,Lambda_b,nk):\n",
    "    \n",
    "    weight = (nk - 1)/nk\n",
    "    \n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "         Psi_diagonal = weight * Lambda_b.diagonal() / Lambda_w.diagonal()\n",
    "\n",
    "    Psi_diagonal[np.isnan(Psi_diagonal)] = 0.0\n",
    "    Psi_diagonal = Psi_diagonal - 1.0/nk\n",
    "    \n",
    "    # max(0, Psi)\n",
    "    Psi_diagonal[Psi_diagonal < 0.0] = 0.0\n",
    "    \n",
    "    Psi_diagonal[np.isinf(Psi_diagonal)] = 0.0\n",
    "    Psi = np.diag(Psi_diagonal)\n",
    "\n",
    "    return Psi\n",
    "\n",
    "\n",
    "def plda_fit(X, y):\n",
    "   \n",
    "    N = X.shape[0]\n",
    "    K = np.size(np.unique(y))\n",
    "    labels = np.unique(y)\n",
    "    nk = N/K\n",
    "    \n",
    "    global_mean = np.mean(X,axis=0)\n",
    "    \n",
    "    Sw, Sb = compute_scatter_matrixes(X,y,nk)\n",
    "    \n",
    "    A, W = compute_transformation_matrix(Sw,Sb,nk)\n",
    "    \n",
    "    Lambda_w = diagnolize_matrix(Sw,W)\n",
    "    Lambda_b = diagnolize_matrix(Sb,W)\n",
    "   \n",
    "    # The within trasnformed covariance is Identity matrix\n",
    "    Psi = compute_transformed_between_covariance(Lambda_w,Lambda_b,nk)\n",
    "   \n",
    "    return global_mean, A, Psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:01:28.644821Z",
     "start_time": "2019-06-03T21:01:28.639179Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier = plda.Classifier(X, y)\n",
    "classifier.fit_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:01:29.245587Z",
     "start_time": "2019-06-03T21:01:29.230969Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 28.9906, -52.5728],\n",
       "       [-52.5728, 139.6685]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 28.9906, -52.5728],\n",
       "       [-52.5728, 139.6685]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[2779.8685, 2788.6271],\n",
       "       [2788.6271, 2798.6723]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[2779.8685, 2788.6271],\n",
       "       [2788.6271, 2798.6723]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sw,Sb = compute_scatter_matrixes(X,y,nk)\n",
    "\n",
    "Sw\n",
    "classifier.model.S_w\n",
    "\n",
    "Sb\n",
    "classifier.model.S_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:01:32.220218Z",
     "start_time": "2019-06-03T21:01:32.208507Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0606,  0.324 ],\n",
       "       [ 0.0604,  0.1375]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.4689, -0.8833],\n",
       "       [-0.8833, -0.4689]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.linalg import eigh\n",
    "\n",
    "vals, W2 = eigh(Sb, Sw)\n",
    "W2\n",
    "\n",
    "\n",
    "\n",
    "Sw_inv = np.linalg.inv(Sw)\n",
    "d = Sw.shape[0]\n",
    "     \n",
    "S = np.matmul(Sw_inv, Sb)\n",
    "eigen_values, W = np.linalg.eigh(S)\n",
    "W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:01:48.769549Z",
     "start_time": "2019-06-03T21:01:48.753380Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0606,  0.324 ],\n",
       "       [ 0.0604,  0.1375]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.0606,  0.324 ],\n",
       "       [ 0.0604,  0.1375]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[-4.9549,  2.1753],\n",
       "       [11.6755,  2.1824]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[-4.9549,  2.1753],\n",
       "       [11.6755,  2.1824]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, W = compute_transformation_matrix(Sw,Sb, nk)\n",
    "\n",
    "W\n",
    "class_W = classifier.model.calc_W(Sb, Sw)\n",
    "class_W\n",
    "\n",
    "A\n",
    "class_Lambda_w = classifier.model.calc_Î›_w(Sw, W)\n",
    "class_A = classifier.model.calc_A(nk, class_Lambda_w, class_W)\n",
    "class_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:01:53.669101Z",
     "start_time": "2019-06-03T21:01:53.649410Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambdas\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[4.5893e-03, 0.0000e+00],\n",
       "       [0.0000e+00, 5.9338e+02]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phis\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 29.2834, -53.1038],\n",
       "       [-53.1038, 141.0793]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[2779.7096, 2788.8425],\n",
       "       [2788.8425, 2798.0053]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[  0.    ,   0.    ],\n",
       "       [  0.    , 587.4408]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lambda_w = diagnolize_matrix(Sw,W)\n",
    "Lambda_b = diagnolize_matrix(Sb,W)\n",
    "\n",
    "Psi = compute_transformed_between_covariance(Lambda_w,Lambda_b,nk)\n",
    "\n",
    "print('Lambdas')\n",
    "Lambda_w\n",
    "Lambda_b\n",
    "\n",
    "Phi_w = np.matmul(A,A.T)\n",
    "Phi_b = np.matmul(A,np.matmul(Psi,A.T))\n",
    "\n",
    "print('Phis')\n",
    "Phi_w\n",
    "Phi_b\n",
    "\n",
    "Psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:01:58.703093Z",
     "start_time": "2019-06-03T21:01:58.688813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phiw vs Sw\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 29.2834, -53.1038],\n",
       "       [-53.1038, 141.0793]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 29.2834, -53.1038],\n",
       "       [-53.1038, 141.0793]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phib vs Sb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2779.7096, 2788.8425],\n",
       "       [2788.8425, 2798.0053]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[2779.5757, 2789.1581],\n",
       "       [2789.1581, 2797.2615]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Phiw vs Sw')\n",
    "Phi_w \n",
    "(nk/(nk -1)*Sw)\n",
    "\n",
    "print('Phib vs Sb')\n",
    "Phi_b \n",
    "Sb - 1.0/(nk-1)*Sw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:02:01.808516Z",
     "start_time": "2019-06-03T21:02:01.792704Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.6366, 22.3433])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[-4.9549,  2.1753],\n",
       "       [11.6755,  2.1824]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[  0.    ,   0.    ],\n",
       "       [  0.    , 587.4408]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m, A, Psi = plda_fit(X, y)\n",
    "\n",
    "m\n",
    "A\n",
    "Psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:02:05.244601Z",
     "start_time": "2019-06-03T21:02:05.232149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768.9534142888966"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "768.9534142888966"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.00016847525056950914"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## double check transformations\n",
    "\n",
    "u1 = np.matmul(W.T,x_new)\n",
    "\n",
    "A_inv = np.linalg.inv(A)\n",
    "\n",
    "u2 = np.matmul(A_inv,x_new - m)\n",
    "\n",
    "np.dot(u1,u2)\n",
    "\n",
    "np.matmul(u1,u2.T)\n",
    "\n",
    "# u1 n u2 are orthogonal\n",
    "\n",
    "\n",
    "np.arccos(np.matmul(u1/np.linalg.norm(u1),u2.T/np.linalg.norm(u2)))/np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:02:15.871667Z",
     "start_time": "2019-06-03T21:02:15.857338Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.3283e-10, 0.0000e+00],\n",
       "       [0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1404429.5325, 1368027.1627],\n",
       "       [1368027.1627, 1469170.408 ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1404429.5325, 1368027.1627],\n",
       "       [1368027.1627, 1469170.408 ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1404429.5325, 1368027.1627],\n",
       "       [1368027.1627, 1469170.408 ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "St = (N - 1.0)* np.cov(X[:,0],X[:,1])\n",
    "\n",
    "u = np.add(X,-m).transpose()\n",
    "S_hat = np.matmul(u,u.transpose())\n",
    "\n",
    "St - S_hat\n",
    "\n",
    "N*Sw + N*Sb\n",
    "\n",
    "St\n",
    "\n",
    "S_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:02:28.652077Z",
     "start_time": "2019-06-03T21:02:28.641609Z"
    }
   },
   "outputs": [],
   "source": [
    "def project_data(z, M_inv,global_mean):\n",
    "    \n",
    "    z_transformed = np.matmul(M_inv,(z - global_mean).T)\n",
    "    \n",
    "    return z_transformed\n",
    "\n",
    "def plda_predict(X_new,X, y,A_inv, Psi, nk):\n",
    "    \n",
    "    I = np.identity(Psi.shape[0]).diagonal()\n",
    "    \n",
    "    global_mean = np.mean(X,axis=0)\n",
    "    \n",
    "    # u' = A^{-1}(x - m)\n",
    "    U_new = project_data(X_new,A_inv,global_mean)\n",
    "    \n",
    "    #print(X_new.shape)\n",
    "    \n",
    "    prob_max = -np.Infinity\n",
    "    label_max = -1\n",
    "    labels = np.unique(y)\n",
    "    \n",
    "    Psi_diag = Psi.diagonal()\n",
    "    \n",
    "    for label in labels:\n",
    "        \n",
    "        print('label: {}'.format(label))\n",
    "        \n",
    "        Xk = np.squeeze(X[np.argwhere(y == label)])\n",
    "        #print(Xk.shape)\n",
    "        print('mk: {}'.format(Xk.mean(axis=0)))\n",
    "        \n",
    "        U_g = project_data(Xk,A_inv,global_mean)\n",
    "        U_g = U_g.T\n",
    "        #print(U_g.shape)\n",
    "        \n",
    "        u_g_mean = U_g.mean(axis=0)\n",
    "        #print(u_g_mean.shape)\n",
    "      \n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            \n",
    "            mu_g = nk*Psi_diag/(nk*Psi_diag + I)\n",
    "            mu_g = np.diag(mu_g)\n",
    "            mu_g = np.matmul(mu_g,u_g_mean)\n",
    "            \n",
    "            #print('mu_g')\n",
    "            #print(mu_g)\n",
    "            #print(mu_g.shape)\n",
    "  \n",
    "        \n",
    "            Sg = I + Psi_diag/(nk*Psi_diag + I)\n",
    "            Sg = np.diag(Sg)\n",
    "            \n",
    "            #print('Sg')\n",
    "            #print(Sg)\n",
    "            #print(Sg.shape)\n",
    "        \n",
    "        m_normal = multivariate_normal(mean=mu_g, cov=Sg)\n",
    "        \n",
    "        prob = m_normal.pdf(U_new)\n",
    "        \n",
    "        print('prob: {}'.format(prob))\n",
    "        \n",
    "        if prob > prob_max:\n",
    "            prob_max = prob\n",
    "            label_max = label\n",
    "        \n",
    "    return label_max, prob_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:02:31.587591Z",
     "start_time": "2019-06-03T21:02:31.558079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100.,  80.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(500, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.0603,  0.0601],\n",
       "       [ 0.3224,  0.1368]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[  0.    ,   0.    ],\n",
       "       [  0.    , 587.4408]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 0\n",
      "mk: [-78.5916 -79.4483]\n",
      "prob: 0.0\n",
      "label: 1\n",
      "mk: [54.3726 52.1359]\n",
      "prob: 1.2892507908301935e-75\n",
      "label: 2\n",
      "mk: [39.4421 39.732 ]\n",
      "prob: 1.3546112972746592e-136\n",
      "label: 3\n",
      "mk: [26.9044 27.8456]\n",
      "prob: 1.5738451704909042e-204\n",
      "label: 4\n",
      "mk: [71.0554 71.4513]\n",
      "prob: 1.4871899360485543e-25\n",
      "New label\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.4871899360485543e-25"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = np.array([100.0,80.0])\n",
    "\n",
    "X_new\n",
    "X.shape\n",
    "y.unique()\n",
    "A_inv\n",
    "Psi\n",
    "nk\n",
    "\n",
    "y_new, prob = plda_predict(X_new, X, y, A_inv, Psi, nk)\n",
    "\n",
    "print('New label')\n",
    "y_new\n",
    "prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification of the equations on the first sections\n",
    "\n",
    "For the verification of the formulas cited in the firsts sections (See: [Small discussion about how LDA works (Can be skipped)]()), we are going to compute all matrix: $\\hat{\\Sigma_1}$, $\\hat{\\Sigma_2}$ and $S_t$ and compare with the global covariance matrix of the data (the spread of the data conserves) $\\hat{\\Sigma}$. Also because we generated the data using two multivariate Gaussians, we know the true values of the parameters $\\Sigma_1$ and $\\Sigma_2$ and we can compare with our estimations of this parameters.\n",
    "\n",
    "* Estimating the covariances Matrix\n",
    "\n",
    "Computing $\\hat{\\Sigma_k}$ and comparing with the true values $\\Sigma_k$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:02:36.094317Z",
     "start_time": "2019-06-03T21:02:35.904684Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.3334,  0.    ],\n",
       "       [ 0.    , 95.8518]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-4.,  1.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.3112,  5.9898],\n",
       "       [-1.2001, -0.3257],\n",
       "       [-0.1111, -5.6641]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U\n",
      "mk: [1.3112 5.9898]\n",
      "uk.mean: [1.3016 5.882 ]\n",
      "mk: [-1.2001 -0.3257]\n",
      "uk.mean: [-1.2156 -0.1515]\n",
      "mk: [-0.1111 -5.6641]\n",
      "uk.mean: [-0.0355 -5.6097]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(300, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.0168, 0.0403])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  4.,  6., 12., 19., 22., 11., 16.,  6.,  2.]),\n",
       " array([-8.3442, -7.8336, -7.323 , -6.8124, -6.3018, -5.7911, -5.2805,\n",
       "        -4.7699, -4.2593, -3.7487, -3.2381]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy.random import multivariate_normal\n",
    "def gen_Psi():\n",
    "    \"\"\" Diagonal matrix describing the covariance between clusters.\n",
    "    \"\"\"\n",
    "    np.random.seed(2018)\n",
    "    d = 2\n",
    "    Psi = np.diag(10.0/np.random.sample(d))\n",
    "\n",
    "    return Psi\n",
    "\n",
    "def gen_global_mean():\n",
    "    \n",
    "    d = 2\n",
    "    m = np.random.randint(-10.0, 10.0, d).astype(float)\n",
    "    \n",
    "    return m\n",
    "\n",
    "def gen_V_space(Psi):\n",
    "    # v ~ N(v|0,Psi)\n",
    "\n",
    "    n_class = 3\n",
    "    d = Psi.shape[0]\n",
    "    \n",
    "    V = multivariate_normal(np.zeros(d),Psi,n_class)\n",
    "    V = V - V.mean(axis=0)\n",
    "    \n",
    "    return V\n",
    "    \n",
    "def gen_U_space(V):\n",
    "     # u ~ N(u|v,1)\n",
    "    \n",
    "    n_class = V.shape[0]\n",
    "    d = V.shape[1]\n",
    "    \n",
    "    nk = 100\n",
    "\n",
    "    U = []\n",
    "    for k in range(0,n_class):\n",
    "        \n",
    "        mk = V[k,:]\n",
    "        print('mk: {}'.format(mk))\n",
    "        uk = multivariate_normal(mk,np.diag([1.0 , 1.0]),nk)\n",
    "        print('uk.mean: {}'.format(uk.mean(axis=0)))\n",
    "        U.append(uk)\n",
    "    \n",
    "    \n",
    "    U = np.vstack(U)\n",
    "    return U \n",
    "\n",
    "\n",
    "def gen_A(V):\n",
    "    \"\"\" A = [B][inv(Î› ** .5)][Q^T] and assumes same number of data\n",
    "             in each class v. \n",
    "    \"\"\"\n",
    "    d = V.shape[1]\n",
    "    \n",
    "    np.random.seed(2018)\n",
    "    B = np.random.randint(-200, 200, (d, d)).astype(float)\n",
    "    \n",
    "    print(B)\n",
    "    \n",
    "    big_V = np.matmul(V.T, V)  # V is now a scatter matrix.\n",
    "    \n",
    "    print('bigV')\n",
    "    print(big_V)\n",
    "    \n",
    "    vals, vecs = np.linalg.eig(big_V)\n",
    "    \n",
    "    print('eigen vector values')\n",
    "    print(vals)\n",
    "    print(vecs)\n",
    "\n",
    "    A = B / np.sqrt(vals.real)\n",
    "\n",
    "    print('partial A')\n",
    "    print(A)\n",
    "    A = np.matmul(A, vecs.T)\n",
    "\n",
    "    return A\n",
    "\n",
    "Psi = gen_Psi()\n",
    "Psi\n",
    "\n",
    "m = gen_global_mean()\n",
    "m\n",
    "\n",
    "print('V')\n",
    "\n",
    "V = gen_V_space(Psi)\n",
    "V.shape\n",
    "\n",
    "V\n",
    "\n",
    "print('U')\n",
    "\n",
    "U = gen_U_space(V)\n",
    "U.shape\n",
    "\n",
    "# should be ckose to zero because of V is zero mran\n",
    "U.mean(axis=0)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.hist(U[201:300,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:02:36.491460Z",
     "start_time": "2019-06-03T21:02:36.482113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 50. -98.]\n",
      " [ 26.  65.]]\n",
      "bigV\n",
      "[[ 3.1717  8.8735]\n",
      " [ 8.8735 68.0659]]\n",
      "eigen vector values\n",
      "[ 1.9802 69.2574]\n",
      "[[-0.9911 -0.1331]\n",
      " [ 0.1331 -0.9911]]\n",
      "partial A\n",
      "[[ 35.5315 -11.7759]\n",
      " [ 18.4764   7.8105]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-33.6484,  16.3996],\n",
       "       [-19.3515,  -5.2822]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = gen_A(V)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:02:37.514150Z",
     "start_time": "2019-06-03T21:02:37.503010Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "compute_scatter_matrixes() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-e8e2a989606f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mSw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_scatter_matrixes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: compute_scatter_matrixes() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "U_labels = ([1] * 100) + ([2] * 100) + ([3] * 100)\n",
    "y = np.array(U_labels)\n",
    "\n",
    "Phi_w = np.matmul(A,A.T)\n",
    "\n",
    "nk = 100\n",
    "\n",
    "Sw,Sb = compute_scatter_matrixes(X,y,np.unique(y),nk)\n",
    "\n",
    "\n",
    "Phi_w\n",
    "\n",
    "Sw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:02:38.200495Z",
     "start_time": "2019-06-03T21:02:38.175150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0000e+00, -2.7756e-17],\n",
       "       [ 0.0000e+00,  1.0000e+00]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(300, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.0938, -0.5388])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-180.957 , -103.2178])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([163.1598,  69.2848])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(300, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-3.9062,  0.4612])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-4.,  1.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.0235, 0.5388])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_inv = np.linalg.inv(A)\n",
    "\n",
    "np.matmul(A_inv,A)\n",
    "\n",
    "Au =  np.matmul(A, U.T).T\n",
    "\n",
    "Au.shape\n",
    "\n",
    "Au.mean(axis=0)\n",
    "Au.min(axis=0)\n",
    "Au.max(axis=0)\n",
    "\n",
    "\n",
    "X = m + Au\n",
    "X.shape\n",
    "\n",
    "X.mean(axis=0)\n",
    "m\n",
    "\n",
    "(m - X.mean(axis=0))/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Tranformed centorid os each class (Good for verofocation)\n",
    "Av =  np.matmul(A, V.T).T\n",
    "Y = m + Av \n",
    "Y.shape\n",
    "\n",
    "Y\n",
    "\n",
    "X1 = X[0:100,:]\n",
    "x_bar = np.mean(X1,axis=0)\n",
    "\n",
    "# Comparing the true parameter Y_1 with the estimation of this parmeter\n",
    "Y[0,:]\n",
    "x_bar\n",
    "\n",
    "(Y[0,:] - x_bar)/Y[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_labels = ([1] * 100) + ([2] * 100) + ([3] * 100)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.scatter(U[:, 0], U[:, 1], c=U_labels, s=40, cmap='viridis', zorder=2)\n",
    "ax.scatter(V[:, 0], V[:, 1], c='red', s=40, cmap='viridis', zorder=2)\n",
    "ax.scatter(0, 0, c='blue', s=40, cmap='viridis', zorder=2)\n",
    "ax.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.scatter(X[:, 0], X[:, 1], c=U_labels, s=40, cmap='viridis', zorder=2)\n",
    "ax.scatter(Y[:, 0], Y[:, 1], c='red', s=40, cmap='viridis', zorder=2)\n",
    "ax.scatter(m[0], m[1], c='blue', s=40, cmap='viridis', zorder=2)\n",
    "ax.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(U_labels)\n",
    "\n",
    "plda_m, plda_A, plda_Psi = plda_fit(X, y)\n",
    "\n",
    "print('A')\n",
    "A\n",
    "plda_A\n",
    "\n",
    "print('Psi')\n",
    "Psi\n",
    "plda_Psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plda_Phi_w = np.matmul(plda_A,plda_A.T)\n",
    "plda_Phi_w\n",
    "\n",
    "X1 = X[0:100,:]\n",
    "X2 = X[100:200,:]\n",
    "X3 = X[200:300,:]\n",
    "\n",
    "print('S1')\n",
    "S1 = np.cov(X1[:,0],X1[:,1])\n",
    "S1\n",
    "\n",
    "print('S2')\n",
    "S2 = np.cov(X2[:,0],X2[:,1])\n",
    "S2\n",
    "\n",
    "print('S3')\n",
    "S3 = np.cov(X3[:,0],X3[:,1])\n",
    "S3\n",
    "\n",
    "print('AVG: (S1 + S2 + S3)/3')\n",
    "S_avg  = (S1 + S2 + S3)/3\n",
    "\n",
    "S_avg\n",
    "\n",
    "(plda_Phi_w - S_avg)/plda_Phi_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi_w = np.matmul(A,A.T)\n",
    "\n",
    "plda_Phi_w\n",
    "Phi_w\n",
    "\n",
    "(Phi_w - plda_Phi_w)/Phi_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the number of class (small sample size)\n",
    "# The error is big see: 2018-07-19-lhof-study_understand_code_n_unit_test_code\n",
    "\n",
    "Phi_b =  np.matmul(A,np.matmul(Psi,A.T))\n",
    "plda_Phi_b = np.matmul(plda_A,np.matmul(plda_Psi,plda_A.T))\n",
    "\n",
    "Phi_b\n",
    "plda_Phi_b\n",
    "\n",
    "(Phi_b - plda_Phi_b)/Phi_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
