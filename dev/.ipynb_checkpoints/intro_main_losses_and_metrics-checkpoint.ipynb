{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy implementation of main losses and metrics\n",
    "\n",
    "**WIP**\n",
    "\n",
    "Implment in numpy the most common losses and metrics. Compare with tensorflow implemnattion and write a brief intro.\n",
    "\n",
    "Try to dicuss aplication. pros and crons and properties\n",
    "\n",
    "**GOAL:** \n",
    " \n",
    " what\n",
    " 1. equations and properties\n",
    " 1. pros and crons\n",
    " 1. aplications\n",
    " \n",
    " losse and metrics\n",
    " 1. binary cross entropy\n",
    " 1. cross entropy  \n",
    "     * relation with the binary loss\n",
    " 1. categorical and sparse categorical cross entropy\n",
    "     * relation with cross entropy loss\n",
    " 1. mae, mse and mape\n",
    "     * the impact of large vs small errors (mse penalises more large error)\n",
    "     * show best consant estimator (mean for mse and median for mae)\n",
    "\n",
    "refs:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* NOTE: list of todos\n",
    "* DONE: ~~understand the sparse categorical loss equation. ~~\n",
    "     1. ~~Implement it using numpy.Softmax, categorical and sparse categorical cross entropy~~\n",
    "     1. ~~Run some examples~~ ok\n",
    "     1. ~~show the lead to same reulst and the diff is the label format~~\n",
    "     1. ~~prove categorcal cross entropy = softmax + cross entropy loss~~\n",
    "     1. see: https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy\n",
    "             https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy\n",
    "             https://gombru.github.io/2018/05/23/cross_entropy_loss/  <== looks good \n",
    "             https://stackoverflow.com/questions/59787897/how-does-tensorflow-sparsecategoricalcrossentropy-work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds-vm-leandro2\n",
      "2018-06-08-lhof-running_gmm_em_code_from_mcdickenson.ipynb\n",
      "2018-06-18-lhof-simulated_data.ipynb\n",
      "2021-10-31-lhof-study_learning_rate_finder.ipynb\n",
      "2023-02-10-lhof-study_GANS.ipynb\n",
      "intro_KNN.ipynb\n",
      "intro_batch_normalization.ipynb\n",
      "intro_gradient_algos.ipynb\n",
      "intro_kmeans.ipynb\n",
      "intro_pca.ipynb\n",
      "intro_plda.ipynb\n",
      "intro_reinforcement_learning.ipynb\n",
      "intro_to_prediction_interval.ipynb\n",
      "machine_learning_metrics.ipynb\n"
     ]
    }
   ],
   "source": [
    "!hostname \n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agor vai\n"
     ]
    }
   ],
   "source": [
    "import IPython\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from IPython.display import Image\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "print(\"agor vai\")\n",
    "\n",
    "# import nbformat\n",
    "# from nbformat import v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 07:23:43.487609: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-12 07:23:43.617201: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-12 07:23:43.622967: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-12 07:23:43.622984: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-12 07:23:43.651394: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-12 07:23:44.433293: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-12 07:23:44.433358: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-12 07:23:44.433366: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "pip install nbformat\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand the loss first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/cross-entropy-loss-function-f38c4ec8643e#:~:text=Categorical%20cross%2Dentropy%20is%20used,%5D%20for%203%2Dclass%20problem.\n",
    "\n",
    "The **sparse_categorical_crossentropy** loss function is similar to the categorical_crossentropy loss function, but it is designed for use with integer-encoded class labels. Here's how the sparse_categorical_crossentropy loss function works:\n",
    "\n",
    "1. The true class labels are represented as integers, and the predicted class probabilities are output as a softmax activation.\n",
    "\n",
    "1. The loss function calculates the cross-entropy between the true class labels and the predicted class probabilities.\n",
    "\n",
    "1. The calculated loss value is minimized during the model training process using an optimizer.\n",
    "\n",
    "$\n",
    "L = -\\frac{1}{C}\\sum_{i=1}^{C}{y_{i} \\log(\\hat{(y_{i}})}\n",
    "$\n",
    "\n",
    "\n",
    "where $C$ is the number of classes, $y_{i}$ is the true class label for class $i$, and $\\hat{y_{i}} = f(s_i)$ is the predicted probability for class $i$. The loss is calculated over all classes by taking the sum of the cross-entropy loss for each class.\n",
    "\n",
    "The difference between **categorica crossentropy** and **sparse categorical corss entropy** are\":\n",
    "\n",
    "* categorica crossentropy: true labels are one-hot encoded. Ex. 3-class classification problem [1,0,0], [0,1,0] and [0,0,1].\n",
    "\n",
    "* sparse categorical corss entropy: truth labels are integer encoded. Ex. 1,2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y_true, y_pred):\n",
    "\n",
    "    loss = - np.sum(y_true * np.log(y_pred), axis=-1)\n",
    "    \n",
    "    return np.mean(loss)\n",
    "\n",
    "def softmax(z):\n",
    "    \n",
    "    exp_z = np.exp(z)\n",
    "    \n",
    "    return exp_z / np.sum(exp_z, axis=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.99431072, 0.64088268, 0.95640322],\n",
       "       [0.47087578, 0.36102252, 0.37446763],\n",
       "       [0.58858135, 0.81022701, 0.40814268],\n",
       "       [0.51124761, 0.44928348, 0.34913449]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground True Categorical crossentropy loss: 1.0190051691713176\n",
      "Categorical Cross entropy loss: 1.0190051691713176\n"
     ]
    }
   ],
   "source": [
    "num_classes = 3\n",
    "batch_size = 4\n",
    "y_true = np.random.randint(num_classes, size=(batch_size,)).reshape(-1, 1)\n",
    "y_true = np.eye(num_classes)[y_true.reshape(-1)].reshape(batch_size, num_classes)\n",
    "\n",
    "y_true\n",
    "\n",
    "y_pred = np.random.rand(batch_size, num_classes)\n",
    "y_pred\n",
    "\n",
    "\n",
    "# ground true\n",
    "cce_loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)(y_true, y_pred)\n",
    "print('Ground True Categorical crossentropy loss:', cce_loss.numpy())\n",
    "\n",
    "loss = cross_entropy(y_true, softmax(y_pred))\n",
    "print(f\"Categorical Cross entropy loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1920929e-07"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.92027485"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: testing categorical cross entropy\n",
    "cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "y_true = [[0, 1, 0], [0, 0, 1]]\n",
    "y_pred = [[0.00, 1.0, 0], [0.0, 0.0, 1.]]\n",
    "cce(y_true, y_pred).numpy() # Expected zero\n",
    "\n",
    "\n",
    "y_true = [[0, 1, 0], [0, 0, 1]]\n",
    "y_pred = [[0.01, .1, 0.1], [0.1, 0.1, 0.1]]\n",
    "cce(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3841854e-07"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.192093e-07"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.1769392"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.1769392"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: Showing categorical and sparce categorical croos enteopy are the same\n",
    "# Using 'auto'/'sum_over_batch_size' reduction type.\n",
    "scce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "y_pred = [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]]\n",
    "y_true_scce =  [0,1,2]\n",
    "y_true_cce =  [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "               \n",
    "scce(y_true_scce, y_pred).numpy() # expected zero\n",
    "cce(y_true_cce, y_pred).numpy() # expected zero\n",
    "\n",
    "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
    "y_true_scce = [1, 2]\n",
    "y_true_cce =  [[0, 1, 0], [0, 0, 1]]\n",
    "scce(y_true_scce, y_pred).numpy() # expected > 0\n",
    "cce(y_true_cce, y_pred).numpy() # expected > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical crossentropy loss: 0.6009282\n",
      "Crossentropy loss using softmax: 0.6009282\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Showing that Categorical cross entropy loss = softmax + cross entropy loss\n",
    "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
    "y_true_cce =  [[0, 1, 0], [0, 0, 1]]\n",
    "\n",
    "# Define some example data\n",
    "y_true = tf.constant([[0, 1, 0], [1, 0, 0]])\n",
    "y_pred = tf.constant([[0.05, 0.95, 0], [0.9, 0.05, 0.05]])\n",
    "\n",
    "# Compute the categorical crossentropy loss directly \n",
    "# from_logits=True tells keras to normalize the inputs with softmax \n",
    "cce_loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)(y_true, y_pred)\n",
    "print('Categorical crossentropy loss:', cce_loss.numpy())\n",
    "\n",
    "# Compute the softmax and then the crossentropy loss\n",
    "# from_logits=Fase tells keras to DO NOT normalize the inputs \n",
    "softmax_y_pred = tf.nn.softmax(y_pred)\n",
    "ce_loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(y_true, softmax_y_pred)\n",
    "print('Crossentropy loss using softmax:', ce_loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9073468e-06"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [1]\n",
    "y_pred = [[0, 0.1, 0]]\n",
    "scce(y_true, y_pred).numpy() # expected zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gans-env",
   "language": "python",
   "name": "gans-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "230px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "92274f54c36a370591365d84493a50389ebed307f294330ec188d930f0bcf294"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
